{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open search data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ulb\\SearchEngines_benchmark\\venv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\ulb\\SearchEngines_benchmark\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "from opensearchpy import OpenSearch, helpers\n",
    "import pandas as pd\n",
    "from pprint import pp\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "def ppr(resp):\n",
    "    pp(resp.raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Password caricata con successo.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Recupera la variabile della password dall'ambiente\n",
    "OPENSEARCH_INITIAL_ADMIN_PASSWORD = os.getenv(\"OPENSEARCH_INITIAL_ADMIN_PASSWORD\")\n",
    "OPENSEARCH_URL = os.getenv(\"OPENSEARCH_URL\")  \n",
    "# Verifica che la password sia stata caricata correttamente\n",
    "if OPENSEARCH_INITIAL_ADMIN_PASSWORD:\n",
    "    print(\"Password caricata con successo.\")\n",
    "else:\n",
    "    print(\"Errore nel caricare la password.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connessione a OpenSearch avvenuta con successo!\n"
     ]
    }
   ],
   "source": [
    "client = OpenSearch(\n",
    "    hosts=[OPENSEARCH_URL],\n",
    "    http_auth=(\"admin\", OPENSEARCH_INITIAL_ADMIN_PASSWORD),\n",
    "    use_ssl=False,\n",
    "    verify_certs=False,\n",
    "    ssl_assert_hostname=False,\n",
    "    ssl_show_warn=False\n",
    ")\n",
    "try:\n",
    "    info = client.info()\n",
    "    print(\"Connessione a OpenSearch avvenuta con successo!\")\n",
    "except Exception as e:\n",
    "    print(f\"Errore nella connessione: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading post data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_post(json_chunk, index_):\n",
    "    for line in json_chunk:\n",
    "        yield {\n",
    "            \"_index\": index_,\n",
    "            \"_id\": line.get('Id'),\n",
    "            \"_source\": {\n",
    "                \"Body\": line.get(\"Body\",\"\"),\n",
    "                \"CommentCount\": line.get(\"CommentCount\",\"\"),\n",
    "                \"CreationDate\": line.get(\"CreationDate\",\"\"),\n",
    "                \"OwnerUserId\": line.get(\"OwnerUserId\",\"\")\n",
    "            }\n",
    "        }\n",
    "        \n",
    "def generator_comments(json_chunk, index_):\n",
    "    for line in json_chunk:\n",
    "        yield {\n",
    "            \"_index\": index_,\n",
    "            \"_id\": line.get('Id'),\n",
    "            \"_source\": {\n",
    "                \"Text\": line.get(\"Text\",\"\"),\n",
    "                \"Score\": line.get(\"Score\",\"\"),\n",
    "                \"CreationDate\": line.get(\"CreationDate\",\"\"),\n",
    "                \"UserId\": line.get(\"UserId\",\"\")\n",
    "            }\n",
    "        }\n",
    "\n",
    "\n",
    "def generator_user(json_chunk, index_):\n",
    "    for line in json_chunk:\n",
    "        yield {\n",
    "            \"_index\": index_,\n",
    "            \"_id\": line.get('Id'),\n",
    "            \"_source\": {\n",
    "                \"AboutMe\": line.get(\"AboutMe\",\"\"),\n",
    "                \"CreationDate\": line.get(\"CreationDate\",\"\"),\n",
    "                \"DisplayName\": line.get(\"DisplayName\",\"\"),\n",
    "                \"DownVotes\": line.get(\"DownVotes\",\"\"),\n",
    "                \"LastAccessDate\": line.get(\"LastAccessDate\",\"\"),\n",
    "                \"UpVotes\": line.get(\"UpVotes\",\"\")\n",
    "            }\n",
    "        }\n",
    "\n",
    "def from_chunk_to_client_post(chunk,index_):\n",
    "    json_chunk = chunk.to_dict(\"records\")\n",
    "    return generator_post(json_chunk,index_)\n",
    "\n",
    "def from_chunk_to_client_user(chunk,index_):\n",
    "    json_chunk = chunk.to_dict(\"records\")\n",
    "    return generator_user(json_chunk,index_)\n",
    "\n",
    "def from_chunk_to_client_comments(chunk,index_):\n",
    "    json_chunk = chunk.to_dict(\"records\")\n",
    "    return generator_comments(json_chunk,index_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'html_posts'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.create(\n",
    "    index='html_posts',\n",
    "    body = \n",
    "    {\n",
    "    'settings':{\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"html_analyzer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"char_filter\": [\n",
    "                        \"html_strip\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }, \n",
    "    'mappings':{\n",
    "            \"properties\": {\n",
    "                \"Body\": {\n",
    "                    \"type\": \"text\",\n",
    "                    \"analyzer\": \"html_analyzer\"\n",
    "                },\n",
    "                \"CommentCount\": {\n",
    "                    \"type\": \"integer\"\n",
    "                },\n",
    "                \"CreationDate\": {\n",
    "                    \"type\": \"date\",\n",
    "                    \"format\": \"yyyy-MM-dd HH:mm:ss.SSS\"\n",
    "                },\n",
    "                \"OwnerUserId\": {\n",
    "                    \"type\": \"integer\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1566it [12:16,  2.13it/s]\n"
     ]
    }
   ],
   "source": [
    "columns = ['Id', 'OwnerUserId','Body', 'CommentCount', \"CreationDate\"]\n",
    "for chunk in tqdm(pd.read_csv('data/Posts.csv', chunksize=1000)):\n",
    "    gen = from_chunk_to_client_post(chunk[columns], index_='html_posts')\n",
    "    res = helpers.bulk(client, gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.indices.create(\n",
    "    index=\"posts_analyzed_v2\",\n",
    "    body={\n",
    "        \"settings\": {\n",
    "            \"analysis\": {\n",
    "                \"analyzer\": {\n",
    "                    \"custom_text_analyzer\": {\n",
    "                        \"type\": \"standard\",\n",
    "                        \"stopwords\": \"_english_\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"Body\": {\n",
    "                    \"type\": \"text\",\n",
    "                    \"analyzer\": \"custom_text_analyzer\",\n",
    "                    \"fielddata\": True\n",
    "                },\n",
    "                \"CommentCount\": {\"type\": \"long\"},\n",
    "                \"CreationDate\": {\n",
    "                    \"type\": \"date\",\n",
    "                    \"format\": \"yyyy-MM-dd HH:mm:ss.SSS\"  # Example formats\n",
    "                },\n",
    "                \"OwnerUserId\": {\"type\": \"long\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.reindex(\n",
    "    body={\n",
    "        \"source\": {\"index\": \"html_posts\"},\n",
    "        \"dest\": {\"index\": \"posts_analyzed_v2\"}\n",
    "    },\n",
    "    request_timeout=1000  # Increase timeout if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch and print all indices\n",
    "indices = client.cat.indices(format=\"json\")  # Fetch in JSON format for easier processing\n",
    "for index in indices:\n",
    "    print(f\"Index: {index['index']}, Health: {index['health']}, Docs Count: {index['docs.count']}, Size: {index['store.size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uploading comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'comments' deleted successfully!\n"
     ]
    }
   ],
   "source": [
    "# # index name to delete\n",
    "index_name = \"comments\"  # Replace with the name of the index you want to delete\n",
    "\n",
    "# Delete the index\n",
    "try:\n",
    "    response = client.indices.delete(index=index_name)\n",
    "    print(f\"Index '{index_name}' deleted successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting index '{index_name}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'comments'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.indices.create(\n",
    "    index=\"comments\",\n",
    "    body={\n",
    "        \"settings\": {\n",
    "            \"analysis\": {\n",
    "                \"analyzer\": {\n",
    "                    \"custom_text_analyzer\": {\n",
    "                        \"type\": \"standard\",\n",
    "                        \"stopwords\": \"_english_\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"Text\": {\n",
    "                    \"type\": \"text\",\n",
    "                    \"analyzer\": \"custom_text_analyzer\",\n",
    "                    \"fielddata\": True\n",
    "                },\n",
    "                \"Score\": {\"type\": \"long\"},\n",
    "                \"CreationDate\": {\n",
    "                    \"type\": \"date\",\n",
    "                    \"format\": \"yyyy-MM-dd HH:mm:ss.SSS\"  # Example formats\n",
    "                },\n",
    "                \"UserId\": {\"type\": \"long\"},\n",
    "                \"Id\": {\"type\": \"long\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'comments': {'mappings': {'properties': {'CreationDate': {'type': 'date', 'format': 'yyyy-MM-dd HH:mm:ss.SSS'}, 'Id': {'type': 'long'}, 'Score': {'type': 'long'}, 'Text': {'type': 'text', 'analyzer': 'custom_text_analyzer', 'fielddata': True}, 'UserId': {'type': 'long'}}}}}\n"
     ]
    }
   ],
   "source": [
    "mapping = client.indices.get_mapping(index=\"comments\")\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1374it [02:19,  9.86it/s]\n"
     ]
    }
   ],
   "source": [
    "columns = ['Id', 'UserId','Text', 'Score', \"CreationDate\"]\n",
    "for chunk in tqdm(pd.read_csv('data/Comments.csv', chunksize=1000)):\n",
    "    # Replace NaN values in the 'UserId' column with a default value, e.g., -1\n",
    "    chunk['UserId'] = chunk['UserId'].fillna(-1).astype(int)  # Replace with a default value like -1\n",
    "    # Ensure all columns conform to expected data types\n",
    "    chunk['Score'] = chunk['Score'].fillna(0).astype(int)\n",
    "    gen = from_chunk_to_client_comments(chunk[columns], index_='comments')\n",
    "    res = helpers.bulk(client, gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uploading User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.indices.create(\n",
    "    index=\"users\",\n",
    "    body={\n",
    "        \"settings\": {\n",
    "            \"analysis\": {\n",
    "                \"analyzer\": {\n",
    "                    \"custom_text_analyzer\": {\n",
    "                        \"type\": \"standard\",\n",
    "                        \"stopwords\": \"_english_\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"AboutMe\": {\n",
    "                    \"type\": \"text\",\n",
    "                    \"analyzer\": \"custom_text_analyzer\",\n",
    "                    \"fielddata\": True\n",
    "                },\n",
    "                \"Score\": {\"type\": \"long\"},\n",
    "                \"CreationDate\": {\n",
    "                    \"type\": \"date\",\n",
    "                    \"format\": \"yyyy-MM-dd HH:mm:ss.SSS\"  # Example formats\n",
    "                },\n",
    "                \"LastAccessDate\": {\n",
    "                    \"type\": \"date\",\n",
    "                    \"format\": \"yyyy-MM-dd HH:mm:ss.SSS\"  # Example formats\n",
    "                },\n",
    "                \"UserId\": {\"type\": \"long\"},\n",
    "                \"Id\": {\"type\": \"long\"},\n",
    "                \"UpVotes\": {\"type\": \"long\"},\n",
    "                \"DownVotes\": {\"type\": \"long\"},\n",
    "                \"DisplayName\":{\"type\": \"text\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [00:09, 10.31it/s]\n"
     ]
    }
   ],
   "source": [
    "columns = ['Id', 'AboutMe', 'CreationDate','DisplayName', 'DownVotes','LastAccessDate','UpVotes']\n",
    "for chunk in tqdm(pd.read_csv('data/Users.csv', chunksize=1000)):\n",
    "    chunk['AboutMe'] = chunk['AboutMe'].fillna(\" \")\n",
    "    chunk['DisplayName'] = chunk['DisplayName'].fillna(\" \")\n",
    "    gen = from_chunk_to_client_user(chunk[columns], index_='users')\n",
    "    res = helpers.bulk(client, gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
